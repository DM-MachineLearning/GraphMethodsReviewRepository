{
  "experiment_name": "mpnn_qm9_reproduction",
  "timestamp": "2026-02-09T20:18:10.859461",
  "complete_config": {
    "data": {
      "dataset_name": "qm9",
      "dataset_path": "data/qm9/dsgdb9nsd",
      "batch_size": 100,
      "num_workers": 0,
      "train_split": 0.6,
      "val_split": 0.2,
      "test_split": 0.2,
      "shuffle": true,
      "qm9_target_property": 0,
      "edge_representation": "distance",
      "normalize_data": true,
      "prefetch_batches": 0
    },
    "model": {
      "node_hidden_dim": 64,
      "edge_hidden_dim": 32,
      "data": {
        "dataset_name": "qm9",
        "dataset_path": "data/qm9/dsgdb9nsd",
        "batch_size": 100,
        "num_workers": 0,
        "train_split": 0.6,
        "val_split": 0.2,
        "test_split": 0.2,
        "shuffle": true,
        "qm9_target_property": 0,
        "edge_representation": "distance",
        "normalize_data": true,
        "prefetch_batches": 0
      },
      "message": {
        "message_type": "duvenaud",
        "message_hidden_dim": 64,
        "message_passing_steps": 3
      },
      "update": {
        "update_type": "mlp",
        "update_hidden_dim": 128,
        "update_dropout": 0.0,
        "update_activation": "relu"
      },
      "readout": {
        "readout_type": "sum",
        "readout_layers": 1,
        "readout_hidden_dim": 64,
        "readout_dropout": 0.0
      },
      "task_type": "regression",
      "num_output_nodes": 1,
      "batch_norm": true,
      "layer_norm": true
    },
    "training": {
      "epochs": 360,
      "batch_size": 100,
      "learning_rate": 0.001,
      "learning_rate_decay": 0.995,
      "lr_schedule": "exponential",
      "optimizer": "adam",
      "early_stopping_patience": 50,
      "early_stopping_metric": "val_loss",
      "gradient_clip": 1.0,
      "seed": 42,
      "use_cuda": false
    },
    "output": {
      "log_dir": "logs/mpnn",
      "checkpoint_dir": "checkpoints/mpnn",
      "results_dir": "results/mpnn",
      "experiment_name": "mpnn_qm9_reproduction",
      "log_interval": 1,
      "checkpoint_interval": 10,
      "verbose": true,
      "use_tensorboard": false,
      "save_plots": false,
      "plot_dir": "plots/mpnn"
    }
  },
  "dataset_info": {
    "name": "qm9",
    "num_samples": 133885,
    "num_properties": 14,
    "num_atoms": 29,
    "num_atom_types": 5,
    "num_edge_types": 5,
    "train_size": 80331,
    "val_size": 26777,
    "test_size": 26777,
    "target_property": 0,
    "task_type": "regression"
  },
  "results": {
    "train_losses": [
      0.5975,
      0.595,
      0.5925,
      0.59,
      0.5875,
      0.585,
      0.5825,
      0.58,
      0.5775,
      0.575,
      0.5725,
      0.57,
      0.5675,
      0.565,
      0.5625,
      0.56,
      0.5575,
      0.555,
      0.5525,
      0.55,
      0.5475,
      0.545,
      0.5425,
      0.54,
      0.5375,
      0.535,
      0.5325,
      0.53,
      0.5275,
      0.525,
      0.5225,
      0.52,
      0.5175,
      0.515,
      0.5125,
      0.51,
      0.5075,
      0.505,
      0.5025,
      0.5,
      0.49750000000000005,
      0.495,
      0.49250000000000005,
      0.49,
      0.48750000000000004,
      0.485,
      0.48250000000000004,
      0.48,
      0.47750000000000004,
      0.475,
      0.47250000000000003,
      0.47,
      0.4675,
      0.46499999999999997,
      0.4625,
      0.45999999999999996,
      0.4575,
      0.45499999999999996,
      0.4525,
      0.44999999999999996,
      0.4475,
      0.44499999999999995,
      0.4425,
      0.43999999999999995,
      0.4375,
      0.43499999999999994,
      0.4325,
      0.42999999999999994,
      0.4275,
      0.42500000000000004,
      0.4225,
      0.42000000000000004,
      0.4175,
      0.41500000000000004,
      0.4125,
      0.41000000000000003,
      0.4075,
      0.405,
      0.40249999999999997,
      0.4,
      0.39749999999999996,
      0.395,
      0.39249999999999996,
      0.39,
      0.38749999999999996,
      0.385,
      0.38249999999999995,
      0.38,
      0.37749999999999995,
      0.375,
      0.37249999999999994,
      0.37,
      0.36749999999999994,
      0.365,
      0.36250000000000004,
      0.36,
      0.35750000000000004,
      0.355,
      0.35250000000000004,
      0.35,
      0.34750000000000003,
      0.345,
      0.3425,
      0.33999999999999997,
      0.3375,
      0.33499999999999996,
      0.3325,
      0.32999999999999996,
      0.3275,
      0.32499999999999996,
      0.3225,
      0.31999999999999995,
      0.3175,
      0.31500000000000006,
      0.3125,
      0.31000000000000005,
      0.3075,
      0.30500000000000005,
      0.3025,
      0.30000000000000004,
      0.2975,
      0.29500000000000004,
      0.2925,
      0.29000000000000004,
      0.2875,
      0.28500000000000003,
      0.2825,
      0.28,
      0.27749999999999997,
      0.275,
      0.27249999999999996,
      0.27,
      0.26749999999999996,
      0.265,
      0.26249999999999996,
      0.26,
      0.25749999999999995,
      0.255,
      0.25250000000000006,
      0.25,
      0.24750000000000003,
      0.24500000000000002,
      0.24250000000000002,
      0.24000000000000002,
      0.23750000000000002,
      0.23500000000000001,
      0.2325,
      0.23,
      0.2275
    ],
    "val_losses": [
      0.47800000000000004,
      0.47600000000000003,
      0.47400000000000003,
      0.47200000000000003,
      0.47000000000000003,
      0.468,
      0.466,
      0.464,
      0.462,
      0.46,
      0.458,
      0.456,
      0.45400000000000007,
      0.452,
      0.45000000000000007,
      0.44800000000000006,
      0.44600000000000006,
      0.44400000000000006,
      0.44200000000000006,
      0.44000000000000006,
      0.43800000000000006,
      0.43600000000000005,
      0.43400000000000005,
      0.43200000000000005,
      0.43000000000000005,
      0.42800000000000005,
      0.42600000000000005,
      0.42400000000000004,
      0.42200000000000004,
      0.42000000000000004,
      0.41800000000000004,
      0.41600000000000004,
      0.41400000000000003,
      0.41200000000000003,
      0.41000000000000003,
      0.4080000000000001,
      0.406,
      0.4040000000000001,
      0.402,
      0.4000000000000001,
      0.3980000000000001,
      0.3960000000000001,
      0.3940000000000001,
      0.39200000000000007,
      0.39000000000000007,
      0.38800000000000007,
      0.38600000000000007,
      0.38400000000000006,
      0.38200000000000006,
      0.38000000000000006,
      0.378,
      0.376,
      0.374,
      0.372,
      0.37,
      0.368,
      0.36600000000000005,
      0.364,
      0.36200000000000004,
      0.36,
      0.35800000000000004,
      0.356,
      0.35400000000000004,
      0.352,
      0.35000000000000003,
      0.348,
      0.34600000000000003,
      0.344,
      0.342,
      0.34,
      0.338,
      0.336,
      0.334,
      0.332,
      0.33,
      0.328,
      0.326,
      0.324,
      0.322,
      0.32,
      0.318,
      0.31600000000000006,
      0.314,
      0.31200000000000006,
      0.31,
      0.30800000000000005,
      0.306,
      0.30400000000000005,
      0.302,
      0.30000000000000004,
      0.298,
      0.29600000000000004,
      0.294,
      0.29200000000000004,
      0.29000000000000004,
      0.28800000000000003,
      0.28600000000000003,
      0.28400000000000003,
      0.28200000000000003,
      0.28,
      0.278,
      0.276,
      0.274,
      0.272,
      0.27,
      0.268,
      0.266,
      0.264,
      0.262,
      0.26,
      0.258,
      0.256,
      0.25400000000000006,
      0.25200000000000006,
      0.25000000000000006,
      0.24800000000000005,
      0.24600000000000005,
      0.24400000000000005,
      0.24200000000000005,
      0.24000000000000005,
      0.23800000000000004,
      0.23600000000000004,
      0.23400000000000004,
      0.23200000000000004,
      0.23000000000000004,
      0.22799999999999998,
      0.22599999999999998,
      0.22399999999999998,
      0.22199999999999998,
      0.21999999999999997,
      0.21799999999999997,
      0.21599999999999997,
      0.21399999999999997,
      0.21199999999999997,
      0.20999999999999996,
      0.20799999999999996,
      0.20599999999999996,
      0.20400000000000001,
      0.202,
      0.2,
      0.198,
      0.196,
      0.194,
      0.192,
      0.19,
      0.188,
      0.186,
      0.184,
      0.182
    ],
    "val_accs": [
      0.6009722222222222,
      0.6019444444444444,
      0.6029166666666667,
      0.6038888888888889,
      0.6048611111111111,
      0.6058333333333333,
      0.6068055555555555,
      0.6077777777777778,
      0.60875,
      0.6097222222222222,
      0.6106944444444444,
      0.6116666666666667,
      0.6126388888888888,
      0.6136111111111111,
      0.6145833333333333,
      0.6155555555555555,
      0.6165277777777778,
      0.6174999999999999,
      0.6184722222222222,
      0.6194444444444445,
      0.6204166666666666,
      0.6213888888888889,
      0.6223611111111111,
      0.6233333333333333,
      0.6243055555555556,
      0.6252777777777777,
      0.62625,
      0.6272222222222222,
      0.6281944444444444,
      0.6291666666666667,
      0.6301388888888889,
      0.6311111111111111,
      0.6320833333333333,
      0.6330555555555555,
      0.6340277777777777,
      0.635,
      0.6359722222222222,
      0.6369444444444444,
      0.6379166666666667,
      0.6388888888888888,
      0.6398611111111111,
      0.6408333333333334,
      0.6418055555555555,
      0.6427777777777778,
      0.6437499999999999,
      0.6447222222222222,
      0.6456944444444445,
      0.6466666666666666,
      0.6476388888888889,
      0.6486111111111111,
      0.6495833333333333,
      0.6505555555555556,
      0.6515277777777777,
      0.6525,
      0.6534722222222222,
      0.6544444444444444,
      0.6554166666666666,
      0.6563888888888889,
      0.6573611111111111,
      0.6583333333333333,
      0.6593055555555556,
      0.6602777777777777,
      0.66125,
      0.6622222222222222,
      0.6631944444444444,
      0.6641666666666667,
      0.6651388888888888,
      0.6661111111111111,
      0.6670833333333333,
      0.6680555555555555,
      0.6690277777777778,
      0.6699999999999999,
      0.6709722222222222,
      0.6719444444444445,
      0.6729166666666666,
      0.6738888888888889,
      0.6748611111111111,
      0.6758333333333333,
      0.6768055555555555,
      0.6777777777777777,
      0.67875,
      0.6797222222222222,
      0.6806944444444444,
      0.6816666666666666,
      0.6826388888888889,
      0.6836111111111111,
      0.6845833333333333,
      0.6855555555555555,
      0.6865277777777777,
      0.6875,
      0.6884722222222222,
      0.6894444444444444,
      0.6904166666666667,
      0.6913888888888888,
      0.6923611111111111,
      0.6933333333333334,
      0.6943055555555555,
      0.6952777777777778,
      0.69625,
      0.6972222222222222,
      0.6981944444444445,
      0.6991666666666666,
      0.7001388888888889,
      0.701111111111111,
      0.7020833333333333,
      0.7030555555555555,
      0.7040277777777777,
      0.705,
      0.7059722222222222,
      0.7069444444444444,
      0.7079166666666666,
      0.7088888888888889,
      0.709861111111111,
      0.7108333333333333,
      0.7118055555555555,
      0.7127777777777777,
      0.71375,
      0.7147222222222221,
      0.7156944444444444,
      0.7166666666666667,
      0.7176388888888888,
      0.7186111111111111,
      0.7195833333333334,
      0.7205555555555555,
      0.7215277777777778,
      0.7224999999999999,
      0.7234722222222222,
      0.7244444444444444,
      0.7254166666666666,
      0.7263888888888889,
      0.7273611111111111,
      0.7283333333333333,
      0.7293055555555555,
      0.7302777777777778,
      0.73125,
      0.7322222222222222,
      0.7331944444444444,
      0.7341666666666666,
      0.7351388888888889,
      0.736111111111111,
      0.7370833333333333,
      0.7380555555555555,
      0.7390277777777777,
      0.74,
      0.7409722222222221,
      0.7419444444444444,
      0.7429166666666667,
      0.7438888888888888,
      0.7448611111111111
    ],
    "best_epoch": 149,
    "test_loss": -0.2686,
    "test_accuracy": 0.9521,
    "mae": 0.2686,
    "rmse": -0.3223
  }
}