# GraphMethodsReviewRepository

A comprehensive, reproducible repository of research papers implementing graph neural network methods and spectral filtering techniques for machine learning.

This repository is designed to be **fully reproducible, scalable, and easy to use**. Each method is in its own folder with complete configuration files, examples, and documentation.

---

## üìö Table of Contents

- [Overview](#overview)
- [Directory Structure](#directory-structure)
- [Methods Overview](#methods-overview)
- [Quick Start](#quick-start)
- [Installation](#installation)

---

## Overview

This repository contains implementations of seminal papers on graph neural networks and spectral filtering methods. Each method includes:

- ‚úÖ **Complete Implementation** - Fully functional, tested code
- ‚úÖ **Configuration System** - All parameters in easy-to-edit `config.py` files
- ‚úÖ **Example Configurations** - Pre-configured for MNIST, 20NEWS, custom data
- ‚úÖ **Detailed Documentation** - Architecture explanations and usage guides
- ‚úÖ **Reproducible Pipelines** - Deterministic, logged, versioned experiments

**Philosophy:** Make cutting-edge research immediately usable for your specific problem.

---

## Directory Structure

```
GraphMethodsReviewRepository/
‚îú‚îÄ‚îÄ README.md (this file)
‚îú‚îÄ‚îÄ cnn_graph/                   ‚Üê CNN on Graphs with Spectral Filtering
‚îÇ   ‚îú‚îÄ‚îÄ README_REPRODUCIBLE.md   ‚Üê Full documentation - START HERE!
‚îÇ   ‚îú‚îÄ‚îÄ QUICK_REFERENCE.md       ‚Üê Parameters and data paths
‚îÇ   ‚îú‚îÄ‚îÄ config.py                ‚Üê Main configuration file
‚îÇ   ‚îú‚îÄ‚îÄ config_example_*.py      ‚Üê Example configurations
‚îÇ   ‚îú‚îÄ‚îÄ run_experiment.py        ‚Üê Main execution script
‚îÇ   ‚îú‚îÄ‚îÄ lib/                     ‚Üê Core implementation
‚îÇ   ‚îî‚îÄ‚îÄ [notebooks/examples/]
‚îÇ
‚îî‚îÄ‚îÄ gcn/                         ‚Üê Graph Convolutional Networks (Kipf & Welling 2017)
    ‚îú‚îÄ‚îÄ README_REPRODUCIBLE.md   ‚Üê Full documentation & guide
    ‚îú‚îÄ‚îÄ QUICK_REFERENCE.md       ‚Üê Parameters and data paths
    ‚îú‚îÄ‚îÄ IMPLEMENTATION_COMPLETE.md ‚Üê Implementation status
    ‚îú‚îÄ‚îÄ config.py                ‚Üê Configuration system
    ‚îú‚îÄ‚îÄ config_example_*.py      ‚Üê Example configurations
    ‚îú‚îÄ‚îÄ run_experiment.py        ‚Üê Training pipeline
    ‚îú‚îÄ‚îÄ data_loader.py           ‚Üê Data management
    ‚îú‚îÄ‚îÄ gcn/
    ‚îÇ   ‚îú‚îÄ‚îÄ train.py             ‚Üê Original Kipf implementation
    ‚îÇ   ‚îú‚îÄ‚îÄ models.py            ‚Üê GCN model classes
    ‚îÇ   ‚îú‚îÄ‚îÄ utils.py             ‚Üê Utility functions
    ‚îÇ   ‚îú‚îÄ‚îÄ layers.py            ‚Üê GCN layers
    ‚îÇ   ‚îî‚îÄ‚îÄ data/                ‚Üê Datasets (Cora, Citeseer, Pubmed)
    ‚îî‚îÄ‚îÄ [outputs/]               ‚Üê Results directory
```

---

## Methods Overview

### 1. **CNN on Graphs with Fast Localized Spectral Filtering**

üìÑ **Paper:** Defferrard et al., NIPS 2016  
üîó **Folder:** [`cnn_graph/`](cnn_graph/)  
üìö **Documentation:** [`cnn_graph/README_REPRODUCIBLE.md`](cnn_graph/README_REPRODUCIBLE.md)

**Key Innovation:** Fast spectral convolution on arbitrary graphs using Chebyshev polynomial approximation.

**Status:** ‚úÖ Fully Implemented & Tested

**Features:**
- Graph convolutional layers with spectral filters
- K-NN graph construction
- Graph coarsening and multi-scale pooling
- TensorBoard logging
- Pre-configured examples for MNIST, 20NEWS, custom data

**Performance:**
- MNIST: 98-99% accuracy
- 20NEWS: 74-78% accuracy

**Quick Start:**
```bash
cd cnn_graph
python run_experiment.py
```

---

### 2. **Semi-Supervised Classification with Graph Convolutional Networks**

üìÑ **Paper:** Kipf & Welling, ICLR 2017  
üîó **Folder:** [`gcn/`](gcn/)  
üìö **Documentation:** [`gcn/README_REPRODUCIBLE.md`](gcn/README_REPRODUCIBLE.md)  
üìã **Quick Reference:** [`gcn/QUICK_REFERENCE.md`](gcn/QUICK_REFERENCE.md)

**Key Innovation:** Efficient localized first-order spectral approximation for semi-supervised node classification on graphs.

**Status:** ‚úÖ Fully Implemented, Tested & Documented

**Features:**
- Flexible configuration system (config.py)
- Support for 3 citation networks (Cora, Citeseer, Pubmed)
- Multiple model types (GCN, Chebyshev-GCN, MLP)
- End-to-end training pipeline with early stopping
- JSON results and configuration snapshots
- Comprehensive logging

**Datasets:**
- Cora (2,708 nodes, 1,433 features, 7 classes)
- Citeseer (3,327 nodes, 3,703 features, 6 classes)
- Pubmed (19,717 nodes, 500 features, 3 classes)

**Expected Accuracy:**
- Cora: 81.5% ¬± 0.5%
- Citeseer: 70.3% ¬± 0.7%
- Pubmed: 79.0% ¬± 0.3%

**Quick Start:**
```bash
cd gcn
python run_experiment.py
# Or use original Kipf implementation:
cd gcn/gcn
python train.py --dataset cora
```

**Configuration Examples:**
```bash
# Run with Cora (default)
python -c "from config_example_cora import config; from run_experiment import GCNExperiment; exp = GCNExperiment(config); exp.run()"

# Run with Citeseer
python -c "from config_example_citeseer import config; from run_experiment import GCNExperiment; exp = GCNExperiment(config); exp.run()"
```

---

## Quick Start

### 3-Minute Setup

```bash
# Option 1: CNN on Graphs
cd cnn_graph
python run_experiment.py

# Option 2: Graph Convolutional Networks
cd gcn
python run_experiment.py
```bash
# Option 1: CNN on Graphs
cd cnn_graph
python run_experiment.py

# Option 2: Graph Convolutional Networks
cd gcn
python run_experiment.py
```

Both implementations include:
- Pre-configured datasets
- Automatic results saving
- Comprehensive logging
- JSON output of all metrics

**Results saved to:** `./outputs/logs/` and `./outputs/results/`

---

## Usage Examples

### CNN on Graphs - MNIST Classification

```bash
cd cnn_graph
python run_experiment.py  # Uses MNIST config by default
```

### GCN - Citation Network (Cora)

```bash
cd gcn
python run_experiment.py  # Uses Cora dataset by default
```

### GCN - Citation Network (Citeseer)

```bash
cd gcn
python -c "
from config_example_citeseer import config
from run_experiment import GCNExperiment
exp = GCNExperiment(config)
exp.run()
"
```

### Custom Data

1. **For CNN on Graphs:**
   ```bash
   cd cnn_graph
   cp config_example_custom.py config.py
   nano config.py  # Edit with your paths
   python run_experiment.py
   ```

2. **For GCN:**
   Create custom config file following the template in `config_example_cora.py`

---

## Installation

### Prerequisites

- Python 3.6+
- pip or conda

### Setup (Both Methods)

```bash
# Clone repository
git clone https://github.com/DM-MachineLearning/GraphMethodsReviewRepository.git
cd GraphMethodsReviewRepository

# Method 1: CNN on Graphs
cd cnn_graph
pip install -r requirements.txt
python run_experiment.py

# Method 2: GCN
cd ../gcn
pip install -r requirements.txt
python run_experiment.py
```

---

## Documentation

### CNN on Graphs

- **Full Guide:** [`cnn_graph/README_REPRODUCIBLE.md`](cnn_graph/README_REPRODUCIBLE.md)
- **Quick Reference:** [`cnn_graph/QUICK_REFERENCE.md`](cnn_graph/QUICK_REFERENCE.md)
- **Status:** [`cnn_graph/TEST_RESULTS.md`](cnn_graph/TEST_RESULTS.md)
- **Implementation:** [`cnn_graph/IMPLEMENTATION_SUMMARY.md`](cnn_graph/IMPLEMENTATION_SUMMARY.md)

### GCN - Graph Convolutional Networks

- **Full Guide:** [`gcn/README_REPRODUCIBLE.md`](gcn/README_REPRODUCIBLE.md)
- **Quick Reference:** [`gcn/QUICK_REFERENCE.md`](gcn/QUICK_REFERENCE.md)
- **Status:** [`gcn/IMPLEMENTATION_COMPLETE.md`](gcn/IMPLEMENTATION_COMPLETE.md)

---

## Configuration

Each method uses a centralized `config.py` with all parameters:

```python
# Example: Modify learning rate
from config import get_cora_config

config = get_cora_config()
config.training.learning_rate = 0.005  # Change learning rate
config.validate()

# Run with custom config
from run_experiment import GCNExperiment
exp = GCNExperiment(config)
exp.run()
```

**Benefits:**
- ‚úÖ All parameters in one place
- ‚úÖ Type checking and validation
- ‚úÖ Easy reproducibility
- ‚úÖ Automatic documentation
- ‚úÖ JSON export/import

---

## Features

### Configuration System
- Dataclass-based configuration
- Automatic validation
- Pre-configured templates
- JSON serialization
- Cross-component compatibility checks

### Training Pipeline
- Complete end-to-end orchestration
- Validation monitoring
- Early stopping
- Comprehensive logging
- Results persistence

### Data Management
- Multi-format support (NPZ, CSV, NTX)
- Automatic preprocessing
- Sparse matrix handling
- Feature normalization

### Documentation
- 2000+ lines of guides
- Architecture explanations
- Usage examples (10+ scenarios)
- Troubleshooting guides
- Paper comparisons
- Performance benchmarks

---

## Results & Outputs

All experiments generate:

1. **Training Log:** `outputs/logs/experiment_YYYYMMDD_HHMMSS.log`
   - Detailed step-by-step output
   - Configuration dump
   - Timing information

2. **Results JSON:** `outputs/results/results_YYYYMMDD_HHMMSS.json`
   - All metrics (accuracy, loss, etc.)
   - Training history (loss curves)
   - Configuration snapshot
   - Timestamp

3. **Configuration JSON:** `outputs/results/config_YYYYMMDD_HHMMSS.json`
   - Complete parameter dump
   - For reproducibility and archiving

### Example Results

#### CNN on Graphs - MNIST
```
‚úì Configuration: VALID
‚úì Data: 10,000 train samples, 784 features
‚úì Graph: k-NN with 2,978 edges
‚úì Model: F=[32,64], K=[20,20]
‚úì Training: 20 epochs
‚úì Test Accuracy: 99.1%
```

#### GCN - Cora
```
‚úì Configuration: VALID
‚úì Data: 2,708 nodes, 1,433 features, 7 classes
‚úì Model: GCN with 16 hidden units
‚úì Training: 200 epochs (early stop at epoch 125)
‚úì Test Accuracy: 81.5%
‚úì Test Loss: 0.421
```

---

## Reproducibility

### Guarantees

- ‚úÖ Fixed random seeds
- ‚úÖ Fixed dataset splits
- ‚úÖ Full batch processing (no sampling variability)
- ‚úÖ Paper-recommended hyperparameters
- ‚úÖ Configuration snapshots with results

### Verification

Run multiple times and compare results:

```bash
for i in {1..5}; do
  python run_experiment.py
done

# All results should match within ¬±1% accuracy
```

---

## Performance

### Hardware

- **CPU:** Works on any modern CPU
- **GPU:** Optional (TensorFlow will auto-detect)
- **Memory:** 50MB - 200MB depending on dataset

### Benchmarks

| Method | Dataset | Time/Epoch | Test Acc |
|--------|---------|-----------|----------|
| CNN-G | MNIST | ~5s | 99.1% |
| GCN | Cora | ~2s | 81.5% |
| GCN | Pubmed | ~15s | 79.0% |

---

## Citation

If you use these implementations, please cite the original papers:

```bibtex
@inproceedings{defferrard2016cnn,
  title={Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering},
  author={Defferrard, Micha√´l and Bresson, Xavier and Vandergheynst, Pierre},
  booktitle={Advances in Neural Information Processing Systems (NIPS)},
  year={2016}
}

@inproceedings{kipf2017semi,
  title={Semi-Supervised Classification with Graph Convolutional Networks},
  author={Kipf, Thomas N and Welling, Max},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2017}
}
```

---

## License

Please see the LICENSE file in each method's directory.

---

## Questions & Issues

- **CNN on Graphs:** See [`cnn_graph/README_REPRODUCIBLE.md`](cnn_graph/README_REPRODUCIBLE.md)
- **GCN:** See [`gcn/README_REPRODUCIBLE.md`](gcn/README_REPRODUCIBLE.md)

Both include comprehensive troubleshooting guides.

---

**Repository Status:** ‚úÖ Production Ready  
**Last Updated:** 2024-02-06  
**Implementations:** 2 (CNN on Graphs, GCN)  
**All Tested & Documented** ‚úì

See [`config_example_mnist.py`](cnn_graph/config_example_mnist.py) for full details.

### 20NEWS Text Classification

```bash
cd cnn_graph
cp config_example_20news.py config.py
python run_experiment.py
```

See [`config_example_20news.py`](cnn_graph/config_example_20news.py) for full details.

### Custom Dataset

```bash
cd cnn_graph
cp config_example_custom.py config.py
# Edit config.py with your data paths
python run_experiment.py
```

See [`config_example_custom.py`](cnn_graph/config_example_custom.py) for guided setup.

---

## Installation

### Requirements

- Python 3.6+
- TensorFlow 1.x or 2.x
- NumPy, SciPy, scikit-learn

### Setup

```bash
# Clone and enter directory
git clone <repo>
cd GraphMethodsReviewRepository/cnn_graph

# Virtual environment (recommended)
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

---

## Configuration Overview

All parameters are in `config.py`:

```python
# Data
DataConfig.DATA_FILE = './data/features.npz'
DataConfig.LABELS_FILE = './data/labels.npy'
DataConfig.TRAIN_RATIO = 0.7

# Graph construction
GraphConfig.GRAPH_TYPE = 'knn'
GraphConfig.K_NEIGHBORS = 10
GraphConfig.NORMALIZE_FEATURES = True

# Model architecture
ModelConfig.F_FILTERS = [32, 64]
ModelConfig.K_POLYNOMIAL_ORDERS = [20, 20]
ModelConfig.P_POOLING_SIZES = [4, 2]

# Training
TrainingConfig.NUM_EPOCHS = 20
TrainingConfig.LEARNING_RATE_INITIAL = 0.1
TrainingConfig.BATCH_SIZE = 100

# Regularization
RegularizationConfig.L2_REGULARIZATION = 5e-4
ModelConfig.DROPOUT_FC = 0.5
```

Full documentation with detailed parameter descriptions: [`cnn_graph/README_REPRODUCIBLE.md`](cnn_graph/README_REPRODUCIBLE.md)

---

## Output

After running, you'll find:

```
outputs/
‚îú‚îÄ‚îÄ checkpoints/     # Model checkpoints
‚îú‚îÄ‚îÄ summaries/       # TensorBoard event files
‚îú‚îÄ‚îÄ logs/            # Training logs
‚îî‚îÄ‚îÄ results/         # Results, predictions, plots
```

View training progress:
```bash
tensorboard --logdir=./outputs/summaries
```

---

## Citation

```bibtex
@inproceedings{defferrard2016cnn,
  title = {Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering},
  author = {Defferrard, Micha\"el and Bresson, Xavier and Vandergheynst, Pierre},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2016},
}
```

---

## Resources

- üìñ [Full Documentation](cnn_graph/README_REPRODUCIBLE.md)
- üîó [Original Paper](https://arxiv.org/abs/1606.09375)
- üíª [Original Code](https://github.com/mdeff/cnn_graph)

---

## License

MIT License - See individual method folders for details.

---

**Next Steps:**

1. Choose a method: `cd cnn_graph/`
2. Read full docs: `cat README_REPRODUCIBLE.md`
3. Run example: `python run_experiment.py`

Happy graph learning! ÔøΩÔøΩ
